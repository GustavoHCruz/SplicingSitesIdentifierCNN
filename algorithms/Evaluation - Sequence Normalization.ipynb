{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary for translating a protein into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_list_dict = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T':[0,0,0,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model filename defines the already trained model to be used here.\n",
    "The mod1 filename defines the processed data of the genbank dataset and contains for each sequence:\n",
    "- The complete original sequence that will be used to predict the final sequence with the CNN.\n",
    "- The complete final sequence that is expected as result or a.k.a. y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename_input = \"actin\"\n",
    "mod1_filename_input = \"actin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(f\"../assets/models/{model_filename_input}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert DNA sequence to image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image(array):\n",
    "  image = []\n",
    "  for char in array:\n",
    "    image.append(to_list_dict[char])\n",
    "  \n",
    "  image = np.array(image, np.uint8)\n",
    "\n",
    "  image = Image.fromarray(image)\n",
    "  \n",
    "  resized = image.resize((4, 121))\n",
    "\n",
    "  return np.array(resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence x from a dataset X, first the first start of a possible intron is found and then the first possible end for it. The possible intron is then fed into the model, if it is predicted to be a real intron, the intron position is saved in the list (to be removed later) and then the process of finding possible intron combinations continues from the next possible 'GT' position. If the model predict it as not an intron, the search simply continues finding the next possible combination of 'GT...AG' until it is no longer possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(seq):\n",
    "  seq = seq.upper()\n",
    "\n",
    "  intron_comb = []\n",
    "  gt_pos = 0\n",
    "  ag_pos = 0\n",
    "\n",
    "  intron_comb = []\n",
    "  gt_pos = seq.find(\"GT\")\n",
    "  while(gt_pos != -1):\n",
    "    ag_pos = seq.find(\"AG\", gt_pos+2)\n",
    "    prediction = 1\n",
    "    while(ag_pos != -1):\n",
    "      current_seq = seq[gt_pos:ag_pos+2]\n",
    "\n",
    "      image_to_predict = convert_to_image(current_seq)\n",
    "\n",
    "      prediction = model.predict(np.array([image_to_predict]), verbose=0)\n",
    "      prediction = round(prediction[0][0])\n",
    "\n",
    "      if prediction == 0:\n",
    "        intron_comb.append(current_seq)\n",
    "        gt_pos = seq.find(\"GT\", ag_pos+1)\n",
    "        ag_pos = -1\n",
    "      else:\n",
    "        ag_pos = seq.find(\"AG\", ag_pos+1)\n",
    "\n",
    "    if prediction != 0:\n",
    "      gt_pos = seq.find(\"GT\", gt_pos+1)\n",
    "\n",
    "  for intron in intron_comb:\n",
    "    seq = seq.replace(intron, \"\")\n",
    "\n",
    "  return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the module 1 data and using it to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits to \"slowkow\" from \"https://gist.github.com/slowkow/06c6dba9180d013dfd82bec217d22eb5\"\n",
    "\n",
    "def nw(x, y, match = 1, mismatch = 1, gap = 1):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    # Optimal score at each possible pair of characters.\n",
    "    F = np.zeros((nx + 1, ny + 1))\n",
    "    F[:,0] = np.linspace(0, -nx * gap, nx + 1)\n",
    "    F[0,:] = np.linspace(0, -ny * gap, ny + 1)\n",
    "    # Pointers to trace through an optimal aligment.\n",
    "    P = np.zeros((nx + 1, ny + 1))\n",
    "    P[:,0] = 3\n",
    "    P[0,:] = 4\n",
    "    # Temporary scores.\n",
    "    t = np.zeros(3)\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            if x[i] == y[j]:\n",
    "                t[0] = F[i,j] + match\n",
    "            else:\n",
    "                t[0] = F[i,j] - mismatch\n",
    "            t[1] = F[i,j+1] - gap\n",
    "            t[2] = F[i+1,j] - gap\n",
    "            tmax = np.max(t)\n",
    "            F[i+1,j+1] = tmax\n",
    "            if t[0] == tmax:\n",
    "                P[i+1,j+1] += 2\n",
    "            if t[1] == tmax:\n",
    "                P[i+1,j+1] += 3\n",
    "            if t[2] == tmax:\n",
    "                P[i+1,j+1] += 4\n",
    "    # Trace through an optimal alignment.\n",
    "    i = nx\n",
    "    j = ny\n",
    "    rx = []\n",
    "    ry = []\n",
    "    while i > 0 or j > 0:\n",
    "        if P[i,j] in [2, 5, 6, 9]:\n",
    "            rx.append(x[i-1])\n",
    "            ry.append(y[j-1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif P[i,j] in [3, 5, 7, 9]:\n",
    "            rx.append(x[i-1])\n",
    "            ry.append('-')\n",
    "            i -= 1\n",
    "        elif P[i,j] in [4, 6, 7, 9]:\n",
    "            rx.append('-')\n",
    "            ry.append(y[j-1])\n",
    "            j -= 1\n",
    "    # Reverse the strings.\n",
    "    rx = ''.join(rx)[::-1]\n",
    "    ry = ''.join(ry)[::-1]\n",
    "    return '\\n'.join([rx, ry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../assets/mod1/\"+mod1_filename_input+\".mod1\", \"rb\")\n",
    "processed_database = pickle.load(file)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_result = []\n",
    "database_len = len(processed_database)\n",
    "progress = 1\n",
    "\n",
    "for sequence in processed_database:\n",
    "  predicted_result = predict_sequence(sequence['complete_sequence'])\n",
    "  comparation_result = nw(predicted_result, sequence['response_sequence'])\n",
    "  a, b = comparation_result.split('\\n')\n",
    "\n",
    "  max_sequence_size = max(len(a), len(b))\n",
    "  min_sequence_size = min(len(a), len(b))\n",
    "\n",
    "  hits = 0\n",
    "  for i in range(min_sequence_size):\n",
    "    if a[i] == b[i]:\n",
    "      hits += 1\n",
    "  normalization_result.append(hits/max_sequence_size)\n",
    "  \n",
    "  normalization_result_array = np.array(normalization_result)\n",
    "  mean = normalization_result_array.mean()\n",
    "\n",
    "  print(f\"Progress: {progress}/{database_len} - Mean: {mean}\")\n",
    "  progress += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_result_array = np.array(normalization_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = normalization_result_array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(array):\n",
    "  limits = np.arange(0.0, 1.1, 0.1)\n",
    "  dict_for_dict = {}\n",
    "  \n",
    "  for i in range(len(limits) - 1):\n",
    "    floor = limits[i]\n",
    "    ceil = limits[i + 1]\n",
    "    count = np.sum((array > floor) & (array <= ceil))\n",
    "    interval = f\"({floor:.1f},{ceil:.1f}]\"\n",
    "    dict_for_dict[interval] = int(count)\n",
    "    \n",
    "  return dict_for_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_dict = distribution(normalization_result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../assets/eval/\"+model_filename_input+\".eval\",\"wb\")\n",
    "pickle.dump({'normalization_result': normalization_result, 'mean': mean, 'distribution': distribution_dict}, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If already exists evaluation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../assets/eval/\"+model_filename_input+\".eval\",\"rb\")\n",
    "data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mean']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
